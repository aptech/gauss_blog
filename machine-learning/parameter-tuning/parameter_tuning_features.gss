new;
library gml;
//rndseed 23423;

/*
** Load data and prepare data
*/
// Load dataset
dataset = __FILE_DIR $+ "reg_data.gdat";
data = loadd(dataset, ". -date");

/*
** Extract outcome and features
*/
// Extract outcome variable
y = data[., "CBO_GAP"];

// Extract features
X = delcols(data, "CBO_GAP");

/*
** Split data into 70% training
** and 30% testing sets
*/
shuffle = "False";
{ y_train, y_test, x_train, x_test } = traintestSplit(Y, X, 0.7, shuffle);

/*
** Settings for decision forest
*/
// Declare an instance of the 
// dfControl structure
struct dfControl dfc;

// Set default values for
// structure members
dfc = dfControlCreate();

// Turn on out-of-bag error calculation
dfc.oobError = 1;

/*
** Initialize grid and
** storage matrices
*/
// Create vector of possible
// features per node values
featuresPerNode = seqa(1, 1, cols(X));
 
// Create storage matrix for oob
oob_error = zeros(rows(featuresPerNode), 1);
 
// Create storage dataframe for MSE
// with one column for training mse
// and one column for testing mse
mse = asDF(zeros(rows(featuresPerNode), 2), "Train", "Test");

for i(1, rows(featuresPerNode), 1);
    
    // Set featuresPerNode parameter
    dfc.featuresPerNode = featuresPerNode[i];
    
    /*
    ** Decision Forest Model
    */
    // Declare 'mdl' to be an instance of a
    // dfModel structure to hold the estimation results
    struct dfModel mdl;

    // Estimate the model with default settings
    mdl = decForestRFit(y_train, x_train, dfc);
    
    // Make predictions using training data
    df_prediction_train = decForestPredict(mdl, x_train);
    
    // Make predictions using testing data
    df_prediction_test = decForestPredict(mdl, x_test);
    
    /*
    ** Compute and store mse
    */
    // Training set MSE
    mse[i, 1] = meanSquaredError(y_train, df_prediction_train);
    
    // Testing set MSE
    mse[i, 2] = meanSquaredError(y_test, df_prediction_test);
    
    // Store oob
    oob_error[i] = mdl.oobError;
endfor;

// Find lowest MSE
ind = minindc(mse[., "Test"]);

print "Optimal features per node setting: "; featuresPerNode[ind];
print "Minimum testing MSE:"; mse[ind, "Test"];


/*
** Plot results
*/
// Set up plot format
struct plotControl plt;
plt = plotGetDefaults("xy");

// Canvas size
plotCanvasSize("px", 600|400);

// Fonts
plotSetFonts(&plt, "ticks legend", "Arial", 12);
plotSetFonts(&plt, "xaxis", "Arial", 16);
plotSetFonts(&plt, "title", "Arial", 18);

// Set up xlabel
plotSetXLabel(&plt, "Features Per Node");

// Place the first Y-tick label at 0.5
// and place additional ticks every 0.25 after
plotSetYTicInterval(&plt, 1, 0);

// Set up legend
plotSetLegend(&plt, "Training"$|"Testing", "top left");

// Title
plotSetTitle(&plt, "Prediction MSE");
//plotLayout(1, 2, 2);
plotXY(plt, featuresPerNode, mse);


